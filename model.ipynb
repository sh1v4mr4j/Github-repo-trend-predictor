{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shivamraj/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OpenIssuesCount  ForksCount  StargazersCount    Size  description_length\n",
      "0               43       27855           331707    1525                  53\n",
      "1              377       33776           316814    5030                  30\n",
      "2              338       28727           306876    1058                  73\n",
      "3               55       76810           306451   22318                  69\n",
      "4               41       39078           296377  243999                 100\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('most_popular_repositories_1000.csv')\n",
    "\n",
    "dataset['Description'] = dataset['Description'].fillna('')\n",
    "dataset['description_length'] = dataset['Description'].apply(len)\n",
    "\n",
    "columns_to_drop = ['Name', 'FullName', 'HtmlUrl', 'Description', 'Language','OwnerLogin', 'OwnerType', 'CreatedAt', 'UpdatedAt', 'PushedAt', 'License','WatchersCount']\n",
    "\n",
    "dataset = dataset.drop(columns=columns_to_drop)\n",
    "\n",
    "ids = dataset['Id']\n",
    "dataset = dataset.drop(columns = ['Id'])\n",
    "\n",
    "\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OpenIssuesCount  ForksCount  StargazersCount      Size  description_length\n",
      "0         0.001405    0.323685           331707  0.000062                  53\n",
      "1         0.012317    0.393350           316814  0.000204                  30\n",
      "2         0.011043    0.333945           306876  0.000043                  73\n",
      "3         0.001797    0.899674           306451  0.000905                  69\n",
      "4         0.001340    0.455732           296377  0.009895                 100\n"
     ]
    }
   ],
   "source": [
    "#normalise\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_to_normalize = ['OpenIssuesCount', 'ForksCount', 'Size', 'description_length']\n",
    "data_to_normalize = dataset[columns_to_normalize]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "dataset[columns_to_normalize] = normalized_data\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.16920966e-01 2.03640300e-01 1.53213288e-02 4.62724936e-03]\n",
      " [9.18090633e-03 1.36811267e-01 7.17448832e-03 3.42759212e-03]\n",
      " [8.03737707e-03 1.09067806e-02 1.97009079e-04 1.74807198e-02]\n",
      " [5.47913876e-02 5.25219724e-02 9.55433205e-03 9.42587832e-03]\n",
      " [2.71179795e-03 2.26724554e-02 4.05129828e-05 6.34104542e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(dataset[['OpenIssuesCount', 'ForksCount', 'Size', 'description_length']])\n",
    "Y = dataset['StargazersCount'].values\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp, ids_train, ids_temp = train_test_split( X, Y, ids, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test, ids_val, ids_test = train_test_split(X_temp, y_temp, ids_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training target and transform it\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "# Apply the same transformation to the validation set\n",
    "y_val_scaled = scaler_target.transform(y_val.reshape(-1, 1))\n",
    "\n",
    "y_test_scaled = scaler_target.transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1692e-01, 2.0364e-01, 1.5321e-02, 4.6272e-03],\n",
      "        [9.1809e-03, 1.3681e-01, 7.1745e-03, 3.4276e-03],\n",
      "        [8.0374e-03, 1.0907e-02, 1.9701e-04, 1.7481e-02],\n",
      "        [5.4791e-02, 5.2522e-02, 9.5543e-03, 9.4259e-03],\n",
      "        [2.7118e-03, 2.2672e-02, 4.0513e-05, 6.3410e-03]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error  # for regression tasks\n",
    "import numpy as np\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # reshape for single output\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)  # Assuming 3 input features\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation for hidden layers\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_val, y_val, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Reshape to column vector\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        predictions = model(X_train_tensor)  # Forward pass\n",
    "        loss = criterion(predictions, y_train_tensor)  # Compute loss\n",
    "        \n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        # Validation step\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "                y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "                val_predictions = model(X_val_tensor)\n",
    "                val_loss = criterion(val_predictions, y_val_tensor)\n",
    "\n",
    "            # Print losses for each epoch\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8r/vk9p_0jn559ggvy1pwy_gczm0000gn/T/ipykernel_32377/47673160.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "/var/folders/8r/vk9p_0jn559ggvy1pwy_gczm0000gn/T/ipykernel_32377/47673160.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Train Loss: 0.0093, Val Loss: 0.0123\n",
      "Epoch [200/1000], Train Loss: 0.0084, Val Loss: 0.0114\n",
      "Epoch [300/1000], Train Loss: 0.0075, Val Loss: 0.0104\n",
      "Epoch [400/1000], Train Loss: 0.0067, Val Loss: 0.0093\n",
      "Epoch [500/1000], Train Loss: 0.0059, Val Loss: 0.0083\n",
      "Epoch [600/1000], Train Loss: 0.0054, Val Loss: 0.0075\n",
      "Epoch [700/1000], Train Loss: 0.0051, Val Loss: 0.0069\n",
      "Epoch [800/1000], Train Loss: 0.0050, Val Loss: 0.0067\n",
      "Epoch [900/1000], Train Loss: 0.0049, Val Loss: 0.0065\n",
      "Epoch [1000/1000], Train Loss: 0.0049, Val Loss: 0.0064\n"
     ]
    }
   ],
   "source": [
    "train(model, X_train, y_train_scaled, X_val, y_val_scaled, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8r/vk9p_0jn559ggvy1pwy_gczm0000gn/T/ipykernel_32377/813048677.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have test data X_test\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred_scaled = model(X_test_tensor)\n",
    "    \n",
    "# Convert the predictions back to the original scale of the target variable\n",
    "y_test_pred = scaler_target.inverse_transform(y_test_pred_scaled.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 33242.81 ]\n",
      " [ 26684.627]\n",
      " [ 32737.352]\n",
      " [147571.72 ]\n",
      " [ 33948.547]\n",
      " [ 25814.445]\n",
      " [ 51810.883]\n",
      " [ 29358.273]\n",
      " [ 26734.504]\n",
      " [ 30791.553]]\n",
      "tensor([[21064.],\n",
      "        [23680.],\n",
      "        [25810.],\n",
      "        [78940.],\n",
      "        [45386.],\n",
      "        [32945.],\n",
      "        [48390.],\n",
      "        [22882.],\n",
      "        [22688.],\n",
      "        [23864.]])\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 19661.2129\n",
      "Mean Squared Error (MSE): 1831776384.0000\n",
      "Root Mean Squared Error (RMSE): 42799.2578\n",
      "R-squared (R²): -0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8r/vk9p_0jn559ggvy1pwy_gczm0000gn/T/ipykernel_32377/1461250871.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Assuming the model is already trained, and you've made predictions on the test set (X_test)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred_scaled = model(X_test_tensor)\n",
    "\n",
    "# Inverse transform the predictions back to original scale if you normalized the target\n",
    "y_test_pred = scaler_target.inverse_transform(y_test_pred_scaled.detach().numpy())\n",
    "\n",
    "# # If you normalized your test labels as well, do the same for y_test\n",
    "# y_test_original = scaler_target.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate the metrics\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rmse = mean_squared_error(y_test, y_test_pred, squared=False)  # RMSE\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print out the metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared (R²): {r2:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
